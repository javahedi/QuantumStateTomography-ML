{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMy3d/UkrIv2MHZeZOMlbY+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javahedi/QuantumStateTomography-ML/blob/main/test_numpy_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b4o2l3ShtvkZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import os\n",
        "import glob\n",
        "import csv\n",
        "import pytest"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um1Fr9c_t9Oz",
        "outputId": "8aefc7df-3d3f-41ed-ec62-b36970dbfbb5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path= \"/content/drive/MyDrive/SL_data/\"\n",
        "cvs_names=glob.glob(f'{path}*.csv')\n",
        "bank_names=glob.glob(f'{path}*bank.npy')\n",
        "weight_names=glob.glob(f'{path}*weights.npy')\n",
        "\n",
        "\n",
        "# Select a single file\n",
        "ind=0\n",
        "with open(f'{cvs_names[ind]}','r') as f:\n",
        "    csvreader =csv.reader(f,delimiter=\",\")\n",
        "    data_list=list(csvreader)\n",
        "\n",
        "\n",
        "banks_list   = []\n",
        "weights_list = []\n",
        "for id, name in enumerate(cvs_names):\n",
        "    bank    = np.load(bank_names[id],mmap_mode=\"r\")\n",
        "    weights = np.load(weight_names[id],mmap_mode=\"r\")\n",
        "    banks_list.append(bank)\n",
        "    weights_list.append(weights)\n",
        "\n",
        "\n",
        "#print(bank.shape)\n",
        "#print(weights.shape)\n",
        "\n",
        "#print(banks_list[-1].shape)\n",
        "#print(weights_list[-1].shape)\n",
        "\n",
        "\n",
        "banks_data    = np.stack(banks_list)\n",
        "weights_data  = np.stack(weights_list)\n",
        "\n",
        "\n",
        "print(banks_data.shape)\n",
        "print(weights_data.shape)\n"
      ],
      "metadata": {
        "id": "UXwF80eHufPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "509d2854-0b27-4612-bae3-082f95d6109d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 100, 100, 2, 2)\n",
            "(1000, 100, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class InfoGain:\n",
        "    def information_gain(self, angles, bank_particles, weights):\n",
        "        angle_dict = {\n",
        "            \"theta\": angles[0],\n",
        "            \"phi\": angles[1]\n",
        "        }\n",
        "        best_guess = np.array(np.einsum('i...,i', bank_particles, weights))\n",
        "        return self.adaptive_cost_func(angle_dict, bank_particles, weights, best_guess, 1)\n",
        "\n",
        "    def adaptive_cost_func(self, angles, rhoBank, weights, bestGuess, nQubits):\n",
        "        meshState = self.angles_to_state_vector(angles, nQubits)\n",
        "        out = np.einsum('ij,ik->ijk', meshState, meshState.conj())\n",
        "        K = self.Shannon_entropy(np.einsum('ijk,kj->i', out, bestGuess))\n",
        "        J = self.Shannon_entropy(np.einsum('ijk,lkj->il', out, rhoBank))\n",
        "        return np.real(K - np.dot(J, weights))\n",
        "\n",
        "    def Shannon_entropy(self, prob):\n",
        "        return np.real(np.sum(-(prob * np.log2(prob)), axis=0))\n",
        "\n",
        "    def angles_to_state_vector(self, angles, nQubits):\n",
        "        if nQubits == 1:\n",
        "            tempMesh = np.array([np.cos(angles[\"theta\"] / 2), np.exp(1j * angles[\"phi\"]) * np.sin(angles[\"theta\"] / 2)])\n",
        "            meshState = np.array([tempMesh, self.get_opposing_state(tempMesh)])\n",
        "        else:\n",
        "            tempMeshA = np.array([np.cos(angles[\"thetaA\"] / 2), np.exp(1j * angles[\"phiA\"]) * np.sin(angles[\"thetaA\"] / 2)])\n",
        "            tempMeshB = np.array([np.cos(angles[\"thetaB\"] / 2), np.exp(1j * angles[\"phiB\"]) * np.sin(angles[\"thetaB\"] / 2)])\n",
        "            meshA = np.array([tempMeshA, self.get_opposing_state(tempMeshA)])\n",
        "            meshB = np.array([tempMeshB, self.get_opposing_state(tempMeshB)])\n",
        "            meshState = np.array([\n",
        "                np.kron(meshA[0], meshB[0]),\n",
        "                np.kron(meshA[0], meshB[1]),\n",
        "                np.kron(meshA[1], meshB[0]),\n",
        "                np.kron(meshA[1], meshB[1])\n",
        "            ])\n",
        "        return meshState\n",
        "\n",
        "    def get_opposing_state(self, meshState):\n",
        "        if meshState[1] == 0:\n",
        "            return np.array([0, 1], dtype=complex)\n",
        "\n",
        "        a = 1\n",
        "        b = -np.conjugate(meshState[0]) / np.conjugate(meshState[1])\n",
        "        norm = np.sqrt(a * np.conjugate(a) + b * np.conjugate(b))\n",
        "        oppositeMeshState = np.array([a / norm, b / norm])\n",
        "        return oppositeMeshState\n",
        "\n",
        "info_gain = InfoGain()"
      ],
      "metadata": {
        "id": "o2T98nv2t3rc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NN_angle_pred=np.array([1,0.75]) # Format as [ theta, phi ]\n",
        "\n",
        "# Select which step in ABME to predict\n",
        "prediction_index=20\n",
        "\n",
        "true_angle=np.array([float(data_list[prediction_index][3]),float(data_list[prediction_index][4])])"
      ],
      "metadata": {
        "id": "CkAH1xWDvidf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NN_angle_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM85ShrOqn_v",
        "outputId": "e976ff5f-9a63-4947-ee62-d9a74abdc15e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.  , 0.75])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_angle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CdgXl5UqpWM",
        "outputId": "0f0afdaf-b0d8-4853-95ee-b71be0322e3e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.2499491, 1.7226485])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "true_info_gain    = info_gain.information_gain(true_angle,bank[prediction_index],weights[prediction_index])\n",
        "NN_pred_info_gain = info_gain.information_gain(NN_angle_pred,bank[prediction_index],weights[prediction_index])\n",
        "print(f'Info gain difference: {true_info_gain - NN_pred_info_gain}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj-VR2rxuvVt",
        "outputId": "3f0a21ba-ea68-4526-8e86-47c5bb505c12"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Info gain difference: 0.00018063078880342642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class InfoGain_np_vectorized:\n",
        "    def information_gain(self, angles, bank_particles, weights):\n",
        "        angle_dict = {\n",
        "            \"theta\": angles[0],\n",
        "            \"phi\": angles[1]\n",
        "        }\n",
        "        best_guess = np.array(np.einsum('i...,i', bank_particles, weights))\n",
        "        return self.adaptive_cost_func(angle_dict, bank_particles, weights, best_guess, 1)\n",
        "\n",
        "\n",
        "\n",
        "    def adaptive_cost_func(self, angles, rhoBank, weights, bestGuess, nQubits):\n",
        "        meshState = self.angles_to_state_vector(angles, nQubits)\n",
        "        out = np.einsum('ij,ik->ijk', meshState, meshState.conj())\n",
        "        K = self.Shannon_entropy(np.einsum('ijk,kj->i', out, bestGuess))\n",
        "        J = self.Shannon_entropy(np.einsum('ijk,lkj->il', out, rhoBank))\n",
        "        return np.real(K - np.dot(J, weights))\n",
        "\n",
        "    def Shannon_entropy(self, prob):\n",
        "        return np.real(np.sum(-(prob * np.log2(prob)), axis=0))\n",
        "\n",
        "    def angles_to_state_vector(self, angles, nQubits):\n",
        "        if nQubits == 1:\n",
        "            tempMesh = np.array([np.cos(angles[\"theta\"] / 2), np.exp(1j * angles[\"phi\"]) * np.sin(angles[\"theta\"] / 2)])\n",
        "            meshState = np.array([tempMesh, self.get_opposing_state(tempMesh)])\n",
        "        else:\n",
        "            tempMeshA = np.array([np.cos(angles[\"thetaA\"] / 2), np.exp(1j * angles[\"phiA\"]) * np.sin(angles[\"thetaA\"] / 2)])\n",
        "            tempMeshB = np.array([np.cos(angles[\"thetaB\"] / 2), np.exp(1j * angles[\"phiB\"]) * np.sin(angles[\"thetaB\"] / 2)])\n",
        "            meshA = np.array([tempMeshA, self.get_opposing_state(tempMeshA)])\n",
        "            meshB = np.array([tempMeshB, self.get_opposing_state(tempMeshB)])\n",
        "            meshState = np.array([\n",
        "                np.kron(meshA[0], meshB[0]),\n",
        "                np.kron(meshA[0], meshB[1]),\n",
        "                np.kron(meshA[1], meshB[0]),\n",
        "                np.kron(meshA[1], meshB[1])\n",
        "            ], dtype=complex)\n",
        "        return meshState\n",
        "\n",
        "    def get_opposing_state(self, meshState):\n",
        "        if meshState[1].all() == 0:\n",
        "            return np.array([0, 1], dtype=complex)\n",
        "\n",
        "        a = 1\n",
        "        b = -np.conjugate(meshState[0]) / np.conjugate(meshState[1])\n",
        "        norm = np.sqrt(a * np.conjugate(a) + b * np.conjugate(b))\n",
        "        oppositeMeshState = np.array([a / norm, b / norm], dtype=complex)\n",
        "        return oppositeMeshState\n",
        "\n",
        "\n",
        "info_gain_vectorized = InfoGain_np_vectorized()\n"
      ],
      "metadata": {
        "id": "krUzsc3mmrq8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_values     = np.stack([np.array([1,0.75]),np.array([1,0.0]),np.array([1,0.5])])\n",
        "priction_indet=[20,40,50]\n",
        "true_angle20=np.array([float(data_list[priction_indet[0]][3]),float(data_list[priction_indet[0]][4])])\n",
        "true_angle40=np.array([float(data_list[priction_indet[1]][3]),float(data_list[priction_indet[1]][4])])\n",
        "true_angle50=np.array([float(data_list[priction_indet[2]][3]),float(data_list[priction_indet[2]][4])])\n",
        "y_true_values        = np.stack([true_angle20,true_angle40,true_angle50])\n",
        "bank_particles_value = np.stack([bank[priction_indet[0]],bank[priction_indet[1]],bank[priction_indet[2]]])\n",
        "weights_value        = np.stack([weights[priction_indet[0]],weights[priction_indet[2]],weights[priction_indet[2]]])\n",
        "\n",
        "print(y_true_values.shape)\n",
        "print(y_predict_values.shape)\n",
        "print(bank_particles_value.shape)\n",
        "print(weights_value.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb6fEoCunKFd",
        "outputId": "0887bb55-a442-426a-d55e-836a6b60a632"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 2)\n",
            "(3, 2)\n",
            "(3, 100, 2, 2)\n",
            "(3, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTCWHU90pWTy",
        "outputId": "bbf5fd83-4413-44f8-f142-33252cb9f8a6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.  , 0.75],\n",
              "       [1.  , 0.  ],\n",
              "       [1.  , 0.5 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJk0q3topYVR",
        "outputId": "72f91283-114a-4522-a82b-602dcc58dcc3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.2499491 ,  1.7226485 ],\n",
              "       [ 1.47249126, -0.38898832],\n",
              "       [ 0.52779046, -0.70772663]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "true_info_gains = np.array([\n",
        "        info_gain_vectorized.information_gain(y_true_val, bank_particles_val, weights_val)\n",
        "        for y_true_val, bank_particles_val, weights_val in zip(y_true_values, bank_particles_value, weights_value)\n",
        "    ])\n",
        "predict_info_gains = np.array([\n",
        "        info_gain_vectorized.information_gain(y_pred_val, bank_particles_val, weights_val)\n",
        "        for y_pred_val, bank_particles_val, weights_val in zip(y_predict_values, bank_particles_value, weights_value)\n",
        "    ])"
      ],
      "metadata": {
        "id": "z4l14J6zm5Nu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_info_gains.sum()/len(true_info_gains)"
      ],
      "metadata": {
        "id": "M2QrfQFsQJ39",
        "outputId": "b765da18-3643-4938-ed0d-6e79e3fd41dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0007745458218840207"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for y1,y2 in zip(predict_info_gains,true_info_gains):\n",
        "    print(f' {y1},     {y2},  and difference: {y2-y1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHbcPXWDoQRT",
        "outputId": "8a3f6fcd-6a89-4a55-9df3-939b7ac8ae22"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.0013689172477217015,     0.001549548036525128,  and difference: 0.00018063078880342642\n",
            " 0.0003878619616848322,     0.00039571630569545935,  and difference: 7.854344010627123e-06\n",
            " 0.0003923231874669031,     0.00037837312343147467,  and difference: -1.3950064035428422e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6HY5rGed4Esl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample input with updated dimensions\n",
        "angles_np         = np.random.rand(32, 100, 2)\n",
        "true_angle        = angles_np + 0.01 * np.random.rand(32, 100, 2)\n",
        "bank_particles_np = np.random.rand(32, 100, 50, 2, 2)\n",
        "weights_np        = np.random.rand(32, 100, 50)\n",
        "print(angles_np.shape)\n",
        "print(bank_particles_np.shape)\n",
        "print(weights_np.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXU1j8pf-xCv",
        "outputId": "41b43609-2678-43aa-d561-a8c9c66fb7ec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 100, 2)\n",
            "(32, 100, 50, 2, 2)\n",
            "(32, 100, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y_true, y_pred, banks, weights, lambda_weight=0.9):\n",
        "\n",
        "    info_gain = InfoGain_np_vectorized()\n",
        "\n",
        "    true_info_gains    = 0\n",
        "    predict_info_gains = 0\n",
        "    for i in range(y_true.shape[0]):\n",
        "        true_info_gains += np.array([\n",
        "                info_gain.information_gain(y_true_val, bank, weight)\n",
        "                for y_true_val, bank, weight in zip(y_true[i,...], banks[i,...], weights[i,...])\n",
        "            ]).sum()/y_true.shape[1]\n",
        "        predict_info_gains += np.array([\n",
        "                info_gain.information_gain(y_pred_val, bank, weight)\n",
        "                for y_pred_val, bank, weight in zip(y_pred[i,...], banks[i,...], weights[i,...])\n",
        "            ]).sum()/y_pred.shape[1]\n",
        "\n",
        "    true_info_gains    /=y_true.shape[0]\n",
        "    predict_info_gains /=y_true.shape[0]\n",
        "\n",
        "    loss_infoGain = 1.0 / predict_info_gains\n",
        "\n",
        "    return loss_infoGain\n"
      ],
      "metadata": {
        "id": "Vev9NpsqGPAr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "    angles_np         = np.random.rand(32, 100, 2)\n",
        "    true_angle        = angles_np + 0.01 * np.random.rand(32, 100, 2)\n",
        "    bank_particles_np = np.random.rand(32, 100, 50, 2, 2)\n",
        "    weights_np        = np.random.rand(32, 100, 50)\n",
        "    output = loss_function(true_angle, angles_np, bank_particles_np, weights_np)\n",
        "\n",
        "    print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apFITMUUGpDN",
        "outputId": "b7eb9d79-e936-44d4-e644-654b0167ede3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.009099908990904038\n",
            "-0.0091297605405524\n",
            "-0.009098407012855473\n",
            "-0.009116362431607893\n",
            "-0.009112758649579179\n",
            "-0.009127038286505407\n",
            "-0.009130459356104688\n",
            "-0.00909509417105675\n",
            "-0.009132914888961603\n",
            "-0.009109659427015006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fWQBXDJBPp_p"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mWc0glOePz9h"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path         = \"/content/drive/MyDrive/SL_data/\"\n",
        "cvs_names    = glob.glob(f'{path}*.csv')\n",
        "bank_names   = glob.glob(f'{path}*bank.npy')\n",
        "weight_names = glob.glob(f'{path}*weights.npy')\n",
        "\n",
        "angles_list  = []\n",
        "banks_list   = []\n",
        "weights_list = []\n",
        "for id, name in enumerate(cvs_names):\n",
        "    data    = np.loadtxt( os.path.join(path,cvs_names[id]),delimiter=',',skiprows=1)\n",
        "    bank    = np.load(bank_names[id],mmap_mode=\"r\")\n",
        "    weights = np.load(weight_names[id],mmap_mode=\"r\")\n",
        "\n",
        "    angles_list.append(data)\n",
        "    banks_list.append(bank[1:])\n",
        "    weights_list.append(weights[1:])\n",
        "\n",
        "angles_data   = np.stack(angles_list)\n",
        "banks_data    = np.stack(banks_list)\n",
        "weights_data  = np.stack(weights_list)\n",
        "\n",
        "print(angles_data.shape)\n",
        "print(banks_data.shape)\n",
        "print(weights_data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0KCSz-kPz6e",
        "outputId": "fd3784ac-79de-46da-8274-10b2bb796658"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 99, 5)\n",
            "(1000, 99, 100, 2, 2)\n",
            "(1000, 99, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the percentage of data to use for validation\n",
        "validation_split = 0.2\n",
        "\n",
        "# Determine the number of samples to use for validation\n",
        "num_validation_samples = int(angles_data.shape[0] * validation_split)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "train_data_angles  = angles_data[:-num_validation_samples]\n",
        "train_data_banks   = banks_data[:-num_validation_samples]\n",
        "train_data_weights = weights_data[:-num_validation_samples]\n",
        "\n",
        "validation_data_angles  = angles_data[-num_validation_samples:]\n",
        "validation_data_banks   = banks_data[-num_validation_samples:]\n",
        "validation_data_weights = weights_data[-num_validation_samples:]"
      ],
      "metadata": {
        "id": "Rex2GF9fPqbf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4TUYoK_aP7y3"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set batch size\n",
        "batch_size = 16\n",
        "\n",
        "# TensorFlow datasets API\n",
        "train_dataset      = tf.data.Dataset.from_tensor_slices((train_data_angles, train_data_banks, train_data_weights)).batch(batch_size)\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_data_angles, validation_data_banks, validation_data_weights)).batch(batch_size)\n"
      ],
      "metadata": {
        "id": "lmxkB29wP5Wt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dimensions of the batches in training dataset\n",
        "for batch_angles, batch_banks, batch_weights in train_dataset.take(1):\n",
        "    print(\"Training Batch Shapes:\")\n",
        "    print(\"Angles Batch Shape:\" , batch_angles.shape)\n",
        "    print(\"Banks Batch Shape:\"  , batch_banks.shape)\n",
        "    print(\"Weights Batch Shape:\", batch_weights.shape)\n",
        "\n",
        "# Check dimensions of the batches in validation dataset\n",
        "for batch_angles, batch_banks, batch_weights in validation_dataset.take(1):\n",
        "    print(\"\\nValidation Batch Shapes:\")\n",
        "    print(\"Angles Batch Shape:\" , batch_angles.shape)\n",
        "    print(\"Banks Batch Shape:\"  , batch_banks.shape)\n",
        "    print(\"Weights Batch Shape:\", batch_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKfqGfWbQFmw",
        "outputId": "710b95cc-f270-44e9-8006-1689eec6fcfa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Batch Shapes:\n",
            "Angles Batch Shape: (16, 99, 5)\n",
            "Banks Batch Shape: (16, 99, 100, 2, 2)\n",
            "Weights Batch Shape: (16, 99, 100)\n",
            "\n",
            "Validation Batch Shapes:\n",
            "Angles Batch Shape: (16, 99, 5)\n",
            "Banks Batch Shape: (16, 99, 100, 2, 2)\n",
            "Weights Batch Shape: (16, 99, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class InfoGainNew:\n",
        "    def information_gain(self, angles,bank_particles,weights):\n",
        "        \"\"\"\n",
        "        Takes in angles as [theta,phi] and bank_particles and weigt as how they are given by the file.\n",
        "        \"\"\"\n",
        "        angle_dict={\n",
        "            \"theta\":angles[0],\n",
        "            \"phi\": angles[1]\n",
        "        }\n",
        "        best_guess=np.array(np.einsum('i...,i',bank_particles,weights))\n",
        "        return self.adaptive_cost_func(angle_dict,bank_particles,weights,best_guess)\n",
        "\n",
        "\n",
        "    def adaptive_cost_func(self, angles,rhoBank,weights,bestGuess):\n",
        "        \"\"\"\n",
        "        Computes the expected entropy reduction of the posterior (likelihood) distribution.\n",
        "        The angles are taken in as a dictionary and indicate what mesaurement is to be perfomred.\n",
        "        Noise correction is currently removed.\n",
        "        \"\"\"\n",
        "        povm=self.angles_to_single_qubit_POVM(angles)\n",
        "        # Computes the entropy of prior and posterior distributions. See 10.1103/PhysRevA.85.052120 for more details.\n",
        "        K=self.Shannon_entropy(np.einsum('ijk,kj->i',povm,bestGuess))\n",
        "        J=self.Shannon_entropy(np.einsum('ijk,lkj->il',povm,rhoBank))\n",
        "        # Returns the negative values such that it becomes a minimization problem rather than maximization problem.\n",
        "        return np.real(K-np.dot(J,weights))\n",
        "\n",
        "\n",
        "    def Shannon_entropy(self, prob):\n",
        "        \"\"\"\n",
        "        Returns the shannon entorpy of the probability histogram.\n",
        "        \"\"\"\n",
        "        return np.real(np.sum(-(prob*np.log2(prob)),axis=0))\n",
        "\n",
        "    def angles_to_single_qubit_POVM(self, angles):\n",
        "        \"\"\"\n",
        "        Takes in measurement angles as dictionaries and returns the spin POVM as 2x2x2 complex array .\n",
        "        For single qubit only.\n",
        "        \"\"\"\n",
        "        up_state_vector=np.array([np.cos(angles[\"theta\"]/2),np.exp(1j*angles[\"phi\"])*np.sin(angles[\"theta\"]/2)],dtype=complex)\n",
        "        up_POVM=np.einsum(\"i,j->ij\",up_state_vector,up_state_vector.conj())\n",
        "        return np.array([up_POVM,np.eye(2)-up_POVM],dtype=complex)\n",
        "\n",
        "\n",
        "\n",
        "info_gain_new = InfoGainNew()"
      ],
      "metadata": {
        "id": "l7XXw_WM7OEF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_values     = np.stack([np.array([1,0.75]),np.array([1,0.0]),np.array([1,0.5])])\n",
        "priction_indet=[20,40,50]\n",
        "true_angle20=np.array([float(data_list[priction_indet[0]][3]),float(data_list[priction_indet[0]][4])])\n",
        "true_angle40=np.array([float(data_list[priction_indet[1]][3]),float(data_list[priction_indet[1]][4])])\n",
        "true_angle50=np.array([float(data_list[priction_indet[2]][3]),float(data_list[priction_indet[2]][4])])\n",
        "y_true_values        = np.stack([true_angle20,true_angle40,true_angle50])\n",
        "bank_particles_value = np.stack([bank[priction_indet[0]],bank[priction_indet[1]],bank[priction_indet[2]]])\n",
        "weights_value        = np.stack([weights[priction_indet[0]],weights[priction_indet[2]],weights[priction_indet[2]]])\n",
        "\n",
        "print(y_true_values.shape)\n",
        "print(y_predict_values.shape)\n",
        "print(bank_particles_value.shape)\n",
        "print(weights_value.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7w-f6EoD3yk",
        "outputId": "64865e4f-16f6-40fd-8279-d3cd854b4ab4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 2)\n",
            "(3, 2)\n",
            "(3, 100, 2, 2)\n",
            "(3, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_info_gains = np.array([\n",
        "        info_gain_new.information_gain(y_true_val, bank_particles_val, weights_val)\n",
        "        for y_true_val, bank_particles_val, weights_val in zip(y_true_values, bank_particles_value, weights_value)\n",
        "    ])\n",
        "predict_info_gains = np.array([\n",
        "        info_gain_new.information_gain(y_pred_val, bank_particles_val, weights_val)\n",
        "        for y_pred_val, bank_particles_val, weights_val in zip(y_predict_values, bank_particles_value, weights_value)\n",
        "    ])"
      ],
      "metadata": {
        "id": "mUoCav_rD5wT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for y1,y2 in zip(predict_info_gains,true_info_gains):\n",
        "    print(f' {y1},     {y2},  and difference: {y2-y1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TVvgYd3IILf",
        "outputId": "2a91b78a-5d89-4a13-a68d-087447dc0ff5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.001368917247721757,     0.001549548036525128,  and difference: 0.0001806307888033709\n",
            " 0.00038786196168494325,     0.0003957163056953483,  and difference: 7.854344010405079e-06\n",
            " 0.0003923231874668476,     0.00037837312343147467,  and difference: -1.3950064035372911e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_info_gains.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlTKOKIgILfi",
        "outputId": "d18e0461-5609-4c58-a6fa-fb7a8d19ffb1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3,)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GFcMHAt1z4vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j0FKZ7kbz4rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wXqH2SYGz4iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InfoGainTF:\n",
        "\n",
        "    def __init__(self, debug=False):\n",
        "        self.debug = debug\n",
        "\n",
        "    @tf.function\n",
        "    def information_gain(self, angles, bank_particles, weights):\n",
        "        best_guess = tf.einsum('i...,i', bank_particles, weights)\n",
        "        return self.adaptive_cost_func(angles, bank_particles, weights, best_guess)\n",
        "\n",
        "    @tf.function\n",
        "    def adaptive_cost_func(self, angles, rho_bank, weights, best_guess):\n",
        "        povm = self.angles_to_single_qubit_POVM(angles)\n",
        "\n",
        "        # Cast tensors to complex64 to match the data type of povm\n",
        "        best_guess = tf.cast(best_guess, dtype=tf.complex64)\n",
        "        rho_bank   = tf.cast(rho_bank, dtype=tf.complex64)\n",
        "\n",
        "        if self.debug:\n",
        "            # Check for NaN values\n",
        "            self.check_numerics(best_guess, 'NaN values found in best_guess')\n",
        "            self.check_numerics(rho_bank, 'NaN values found in rho_bank')\n",
        "\n",
        "        K = self.shannon_entropy(tf.einsum('ijk,kj->i', povm, best_guess))\n",
        "        J = self.shannon_entropy(tf.einsum('ijk,lkj->il', povm, rho_bank))\n",
        "\n",
        "        if self.debug:\n",
        "            # Check for NaN values\n",
        "            self.check_numerics(K, 'NaN values found in K')\n",
        "            self.check_numerics(J, 'NaN values found in J')\n",
        "\n",
        "        return tf.math.real(K - tf.reduce_sum(J * weights))\n",
        "\n",
        "    @staticmethod\n",
        "    def check_numerics(tensor, message):\n",
        "        real_part = tf.math.real(tensor)\n",
        "        imag_part = tf.math.imag(tensor)\n",
        "        tf.debugging.check_numerics(real_part, message=message + ' (Real part)')\n",
        "        tf.debugging.check_numerics(imag_part, message=message + ' (Imaginary part)')\n",
        "\n",
        "    @tf.function\n",
        "    def shannon_entropy(self, prob):\n",
        "        prob_float32 = tf.cast(prob, dtype=tf.float32)\n",
        "        if self.debug:\n",
        "            # Check for NaN values\n",
        "            self.check_numerics(prob_float32, 'NaN values found in prob_float32')\n",
        "        return tf.reduce_sum(-prob_float32 * tf.math.log(prob_float32 + 1e-10) / tf.math.log(2.0), axis=0)\n",
        "\n",
        "    @tf.function\n",
        "    def angles_to_single_qubit_POVM(self, angles):\n",
        "        cos_component = tf.math.cos(angles[0] / 2)\n",
        "        sin_component = tf.math.sin(angles[0] / 2)\n",
        "\n",
        "        complex_part = tf.complex(tf.constant(0.0), angles[1])\n",
        "        up_state_vector = tf.stack([tf.complex(cos_component, 0.0), tf.exp(complex_part) * tf.complex(sin_component, 0.0)], axis=0)\n",
        "\n",
        "        up_POVM = tf.einsum(\"i,j->ij\", up_state_vector, tf.math.conj(up_state_vector))\n",
        "\n",
        "        # Cast tf.eye(2) and up_POVM to complex64 dtype\n",
        "        eye_complex = tf.cast(tf.eye(2), dtype=tf.complex64)\n",
        "        up_POVM = tf.cast(up_POVM, dtype=tf.complex64)\n",
        "\n",
        "        return tf.stack([up_POVM, eye_complex - up_POVM], axis=0)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Pck30xP0WdYd"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "info_gain_tf = InfoGainTF(debug=True)\n",
        "angles = tf.constant([0.1, 0.2], dtype=tf.float32)\n",
        "bank_particles = tf.random.normal((10, 2, 2), dtype=tf.float32)\n",
        "weights = tf.random.normal(shape=(10,), dtype=tf.float32)\n",
        "\n",
        "result = info_gain_tf.information_gain(angles, bank_particles, weights)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q9w5aygAyx1C",
        "outputId": "66eee849-3dc6-45e5-b386-cd8b3c4dbae1"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-d70656cb18e5>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo_gain_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minformation_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbank_particles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node CheckNumerics_4 defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-114-d70656cb18e5>\", line 7, in <cell line: 7>\n\n  File \"<ipython-input-103-9eb565964c85>\", line 9, in information_gain\n\n  File \"<ipython-input-110-86ebb2987e35>\", line 27, in adaptive_cost_func\n\n  File \"<ipython-input-110-86ebb2987e35>\", line 29, in adaptive_cost_func\n\n  File \"<ipython-input-110-86ebb2987e35>\", line 38, in check_numerics\n\nNaN values found in K (Real part) : Tensor had NaN values\n\t [[{{node CheckNumerics_4}}]] [Op:__inference_information_gain_3665]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def test_einsum_operation():\n",
        "    # Generate random data for testing\n",
        "    bank_particles_data = np.random.rand(5, 2, 2).astype(np.float32)\n",
        "    weights_data        = np.random.rand(5).astype(np.float32)\n",
        "\n",
        "    # Convert NumPy arrays to TensorFlow tensors\n",
        "    bank_particles_tf = tf.constant(bank_particles_data)\n",
        "    weights_tf = tf.constant(weights_data)\n",
        "\n",
        "    # Perform einsum operation in TensorFlow\n",
        "    best_guess_tf = tf.einsum('i...,i', bank_particles_tf, weights_tf)\n",
        "\n",
        "    # Perform the same einsum operation in NumPy for comparison\n",
        "    best_guess_np = np.einsum('i...,i', bank_particles_data, weights_data)\n",
        "\n",
        "    # Check if the TensorFlow and NumPy results are close\n",
        "    assert np.allclose(best_guess_tf.numpy(), best_guess_np, rtol=1e-5), \"Test Failed\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vilf71TRhUOG"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the test\n",
        "test_einsum_operation()"
      ],
      "metadata": {
        "id": "yn9vwYVzj7Yo"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def angles_to_single_qubit_POVM_np(angles):\n",
        "    up_state_vector = np.array(\n",
        "        [np.cos(angles[0] / 2), np.exp(1j * angles[1]) * np.sin(angles[0] / 2)],\n",
        "        dtype=complex\n",
        "    )\n",
        "\n",
        "    up_POVM = np.einsum(\"i,j->ij\", up_state_vector, up_state_vector.conj())\n",
        "    return np.array([up_POVM, np.eye(2) - up_POVM], dtype=complex)\n",
        "\n",
        "def angles_to_single_qubit_POVM_tf(angles):\n",
        "    cos_component = tf.math.cos(angles[0] / 2)\n",
        "    sin_component = tf.math.sin(angles[0] / 2)\n",
        "\n",
        "    complex_part = tf.complex(tf.constant(0.0), angles[1])\n",
        "    up_state_vector = tf.stack([tf.complex(cos_component, 0.0), tf.exp(complex_part) * tf.complex(sin_component, 0.0)], axis=0)\n",
        "\n",
        "    up_POVM = tf.einsum(\"i,j->ij\", up_state_vector, tf.math.conj(up_state_vector))\n",
        "\n",
        "    # Cast tf.eye(2) and up_POVM to complex64 dtype\n",
        "    eye_complex = tf.cast(tf.eye(2), dtype=tf.complex64)\n",
        "    up_POVM = tf.cast(up_POVM, dtype=tf.complex64)\n",
        "\n",
        "    return tf.stack([up_POVM, eye_complex - up_POVM], axis=0)\n",
        "\n",
        "def test_POVM():\n",
        "    angles = np.random.rand(2).astype(np.float32)\n",
        "    angles_tf = tf.constant(angles)\n",
        "\n",
        "    # Perform calculations using NumPy\n",
        "    POVM_np = angles_to_single_qubit_POVM_np(angles)\n",
        "\n",
        "    # Perform calculations using TensorFlow\n",
        "    POVM_tf = angles_to_single_qubit_POVM_tf(angles_tf)\n",
        "\n",
        "    # Check if the TensorFlow and NumPy results are close\n",
        "    assert np.allclose(POVM_tf.numpy(), POVM_np, rtol=1e-5), \"Test Failed\"\n",
        "    #tf.debugging.assert_all_close(POVM_np, POVM_tf.numpy(), rtol=1e-5)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y629XmdrpaBk"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the test\n",
        "test_POVM()"
      ],
      "metadata": {
        "id": "tGuyyTkvqXab"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6P42JpO0-JQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IK2jpTDu-JNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To wrap a Python function and use it as a TensorFlow operation using ``tf.numpy_function()``, you need to create a TensorFlow-compatible function that calls your Python function. Here's a general example:"
      ],
      "metadata": {
        "id": "1n6D3mwn-NLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class InfoGainNew(tf.Module):\n",
        "    def __init__(self):\n",
        "        super(InfoGainNew, self).__init__()\n",
        "\n",
        "    def information_gain(self, angles, bank_particles, weights):\n",
        "        result = tf.numpy_function(self.information_gain_py, [angles, bank_particles, weights], tf.float64)\n",
        "        return tf.convert_to_tensor(result, dtype=tf.float64)\n",
        "\n",
        "    def information_gain_py(self, angles, bank_particles, weights):\n",
        "        # Your existing Python code for information_gain\n",
        "        angle_dict = {\"theta\": angles[0], \"phi\": angles[1]}\n",
        "        best_guess = np.array(np.einsum('i...,i', bank_particles, weights))\n",
        "        return self.adaptive_cost_func(angle_dict, bank_particles, weights, best_guess)\n",
        "\n",
        "    def adaptive_cost_func(self, angles,rhoBank,weights,bestGuess):\n",
        "        \"\"\"\n",
        "        Computes the expected entropy reduction of the posterior (likelihood) distribution.\n",
        "        The angles are taken in as a dictionary and indicate what mesaurement is to be perfomred.\n",
        "        Noise correction is currently removed.\n",
        "        \"\"\"\n",
        "        povm=self.angles_to_single_qubit_POVM(angles)\n",
        "        # Computes the entropy of prior and posterior distributions. See 10.1103/PhysRevA.85.052120 for more details.\n",
        "        K=self.Shannon_entropy(np.einsum('ijk,kj->i',povm,bestGuess))\n",
        "        J=self.Shannon_entropy(np.einsum('ijk,lkj->il',povm,rhoBank))\n",
        "        # Returns the negative values such that it becomes a minimization problem rather than maximization problem.\n",
        "        return np.real(K-np.dot(J,weights))\n",
        "\n",
        "\n",
        "    def Shannon_entropy(self, prob):\n",
        "        \"\"\"\n",
        "        Returns the shannon entorpy of the probability histogram.\n",
        "        \"\"\"\n",
        "        return np.real(np.sum(-(prob*np.log2(prob)),axis=0))\n",
        "\n",
        "    def angles_to_single_qubit_POVM(self, angles):\n",
        "        \"\"\"\n",
        "        Takes in measurement angles as dictionaries and returns the spin POVM as 2x2x2 complex array .\n",
        "        For single qubit only.\n",
        "        \"\"\"\n",
        "        up_state_vector=np.array([np.cos(angles[\"theta\"]/2),np.exp(1j*angles[\"phi\"])*np.sin(angles[\"theta\"]/2)],dtype=complex)\n",
        "        up_POVM=np.einsum(\"i,j->ij\",up_state_vector,up_state_vector.conj())\n",
        "        return np.array([up_POVM,np.eye(2)-up_POVM],dtype=complex)\n",
        "\n"
      ],
      "metadata": {
        "id": "1oI8UnVR-JI6"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the InfoGainNew class\n",
        "info_gain_new = InfoGainNew()\n",
        "\n",
        "# Example usage\n",
        "angles_tf = tf.constant([0.1, 0.2], dtype=tf.float64)\n",
        "bank_particles_tf = tf.constant(np.random.rand(10, 2, 2) + 1j * np.random.rand(10, 2, 2), dtype=tf.complex128)\n",
        "weights_tf = tf.constant(np.random.rand(10), dtype=tf.float64)\n",
        "\n",
        "result_tf = info_gain_new.information_gain(angles_tf, bank_particles_tf, weights_tf)\n",
        "\n",
        "# Print the result\n",
        "print(result_tf.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEKXsFaG-ZWe",
        "outputId": "6a07cf99-fae2-4d9f-eb4a-8066742a5b2a"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-12.849417911646256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "angles_tf         = tf.constant(y_predict_values, dtype=tf.float64)\n",
        "bank_particles_tf = tf.constant(bank_particles_value,  dtype=tf.complex128)\n",
        "weights_tf        = tf.constant(weights_value, dtype=tf.float64)\n",
        "\n",
        "\n",
        "print(angles_tf.shape)\n",
        "print(bank_particles_tf.shape)\n",
        "print(weights_tf.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHLSr_hV_LBr",
        "outputId": "e3379a6c-8fe7-445e-d927-f895266bba26"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 2)\n",
            "(3, 100, 2, 2)\n",
            "(3, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "result_tf = info_gain_new.information_gain(angles_tf[0,...], bank_particles_tf[0,...], weights_tf[0,...])\n",
        "\n",
        "# Print the result\n",
        "print(result_tf.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlnNDrtD_W4A",
        "outputId": "91c83e46-a0b7-4e52-d80d-03a10459f575"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.001368917247721757\n"
          ]
        }
      ]
    }
  ]
}